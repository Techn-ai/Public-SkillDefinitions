{
  "name" : "GenAI Security Risk Assessment",
  "name_en" : "GenAI Security Risk Assessment",
  "id" : "029e8baf-6663-4c5f-b2fe-913f4791354d",
  "description" : "GenAI Security Risk Assessment is the systematic process of identifying, evaluating, and mitigating security risks unique to generative artificial intelligence (GenAI) systems. As organizations rapidly adopt GenAI models for tasks such as content creation, code generation, and decision support, new security challenges emerge that differ significantly from traditional IT or machine learning systems. This skill involves understanding and analyzing attack vectors specific to GenAI, such as prompt injection, model inversion, data poisoning, output manipulation, and adversarial attacks. Practitioners must assess risks related to model confidentiality, integrity, and availability, as well as the potential for misuse, data leakage, and unauthorized access to proprietary or sensitive training data. The skill requires familiarity with threat modeling tailored to GenAI architectures (e.g., large language models, diffusion models), evaluation of supply chain vulnerabilities (including third-party model and dataset provenance), and the application of security controls such as input validation, output monitoring, and robust access management. Effective GenAI Security Risk Assessment also considers compliance with emerging standards and regulations (e.g., NIST AI Risk Management Framework, EU AI Act), and integrates with broader organizational security practices, including incident response and continuous monitoring. Immediate applications include pre-deployment risk reviews, ongoing monitoring of deployed GenAI systems, and the development of mitigation strategies to ensure safe, responsible, and resilient AI adoption. This skill is critical today as GenAI systems become integral to business operations, amplifying both their value and their risk profile.\n\nDomain: General\nDomain Description: General skills that don't fit cleanly into other categories\nSkill Type: NotSet\nSkill Areas: Technical, Process\nRelevance Score: 1.2\nGenerated by: Frøya v2.0.0\nOperation ID: FR-20250423-315125e2",
  "description_en" : "GenAI Security Risk Assessment is the systematic process of identifying, evaluating, and mitigating security risks unique to generative artificial intelligence (GenAI) systems. As organizations rapidly adopt GenAI models for tasks such as content creation, code generation, and decision support, new security challenges emerge that differ significantly from traditional IT or machine learning systems. This skill involves understanding and analyzing attack vectors specific to GenAI, such as prompt injection, model inversion, data poisoning, output manipulation, and adversarial attacks. Practitioners must assess risks related to model confidentiality, integrity, and availability, as well as the potential for misuse, data leakage, and unauthorized access to proprietary or sensitive training data. The skill requires familiarity with threat modeling tailored to GenAI architectures (e.g., large language models, diffusion models), evaluation of supply chain vulnerabilities (including third-party model and dataset provenance), and the application of security controls such as input validation, output monitoring, and robust access management. Effective GenAI Security Risk Assessment also considers compliance with emerging standards and regulations (e.g., NIST AI Risk Management Framework, EU AI Act), and integrates with broader organizational security practices, including incident response and continuous monitoring. Immediate applications include pre-deployment risk reviews, ongoing monitoring of deployed GenAI systems, and the development of mitigation strategies to ensure safe, responsible, and resilient AI adoption. This skill is critical today as GenAI systems become integral to business operations, amplifying both their value and their risk profile.",
  "coversElement" : {
    "classification" : "NotSet"
  },
  "taggedWith" : [ ],
  "skillDomains" : [ ],
  "skillAreaCategories" : [ ],
  "matchesArea" : [ {
    "skillAreaClassification" : "Process"
  }, {
    "skillAreaClassification" : "Technical"
  }, {
    "skillAreaClassification" : "NotSet"
  } ],
  "skillType" : {
    "skillTypeClassification" : "NotSet"
  },
  "relatesTo" : [ ],
  "isCompositeOf" : [ ],
  "isExtensionOf" : [ ],
  "additionaljsonproperties" : null,
  "skillOwner" : "668d08a9-810e-440c-a668-531a1624694d",
  "skillOwnerUsername" : "Frøya co-worker",
  "editedBy" : "668d08a9-810e-440c-a668-531a1624694d",
  "editedByUsername" : "Frøya co-worker",
  "networkReference" : null,
  "currentVersion" : 1,
  "createdAt" : [ 2025, 4, 23, 20, 14, 55, 672808000 ],
  "lastEdited" : [ 2025, 4, 23, 20, 14, 55, 672806000 ],
  "hide" : false,
  "public" : false,
  "relatesToSkill" : [ ],
  "isCompositeOfSkill" : [ ],
  "isExtensionOfSkill" : [ ]
}